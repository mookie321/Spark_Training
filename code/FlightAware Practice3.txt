//load in the data frame of the flight position event stream
val df = sqlContext.read.parquet("/Users/mookie_transvoyant/Documents/spark-learning/data/parquetFormat/basic.a8b8080f-538f-455b-8493-11e51b1f0342")

//print schema of the data frame
df.printSchema()

//select some fields of the data frame and create a new data frame
df.registerTempTable("temp")
val myDF = sqlContext.sql("select timestamp, data.flightAwareFlightId,data.altitude, data.latitude, data.longitude from temp"
myDF.show(false)
 
val myDF2 = myDF.withColumn("timestamp_human", from_unixtime(myDF("timestamp").divide(1000)))
val myDF3=myDF2.drop($"timestamp")
val myDF4=myDF3.drop($"timestamp_human")

//convert categorical attribute labels into label indexes
val indexer = new StringIndexer().setInputCol("flightAwareFlightId").setOutputCol("flightIndex")


//convert categorical label indexes into numerical vectors
val encoder = new OneHotEncoder().setInputCol("flightIndex").setOutputCol("flightVec")

//combine all numerical features into a single feature vector
val assembler = new VectorAssembler().setInputCols(Array("altitude","latitude","longitude","flightVec")).setOutputCol("features")

//fit a K-Means model on the extracted features
val kmeans = new KMeans().setK(2).setFeaturesCol("features").setPredictionCol("prediction")

//create pipeline for the kmeans model
val pipeline = new Pipeline().setStages(Array(indexer, encoder, assembler, kmeans))
 
//Predict using K-Means model to get clusters for each data row
val kMeansPredictionModel = pipeline.fit(myDF4)
val predictionResult = kMeansPredictionModel.transform(myDF4)
